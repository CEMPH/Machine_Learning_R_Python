{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4abf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60151353",
   "metadata": {},
   "source": [
    "## Data Import: moisture dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f611ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:\\\\Users\\\\Eugenio_Py\\\\Desktop\\\\Notebooks\\\\datasets\\\\moisture.xlsx\", sheet_name=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4c452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b2700",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285552dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.astype(str) # to make the colnames as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48579b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the scatter plot of Moisture and wavelength in data\n",
    "plt.scatter(data['Moisture'],data['1136'])\n",
    "plt.xlabel(\"1136\")\n",
    "plt.ylabel('Moisture')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6fbc44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# select only numerical attributes\n",
    "X = data.iloc[:, 1:176]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the IR spectra\n",
    "X.T.plot(legend=False,figsize=(16,9));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3453a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = np.arange(1104,2497,8) #wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9c603",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245b7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snv(input_data):\n",
    "  \n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 1:176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57511af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsnv = snv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cf85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44592e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing with Savitzki-Golay - smoothing\n",
    "from scipy.signal import savgol_filter\n",
    "X_savgol = savgol_filter(X, 7, polyorder = 2, deriv=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing with Savitzki-Golay - smoothing and SNV\n",
    "X_savgol = savgol_filter(X, 7, polyorder = 2, deriv=0)\n",
    "X_snv_savgol = snv(X_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684f228",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4,figsize=(15,15))\n",
    "#fig, axs = plt.subplots(2, 2, figsize=(15,15))\n",
    "ax1.plot(wl,  X.T)\n",
    "ax1.set_title('Original data')\n",
    "ax2.plot(wl,  Xsnv.T)\n",
    "ax2.set_title('SNV')\n",
    "ax3.plot(wl,  X_savgol.T)\n",
    "ax3.set_title('Savitzki-Golay - smoothing')\n",
    "ax4.plot(wl,  X_snv_savgol.T)\n",
    "ax4.set_title('Savitzki-Golay - smoothing + SNV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91143ac",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610761ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Define the PCA object\n",
    "pca = PCA()\n",
    " \n",
    "# Run PCA producing the reduced variable Xreg and select the first 10 components\n",
    "pca = PCA(n_components=10)\n",
    "Xreg = pca.fit_transform(X_snv_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d73bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y for PCR and PLS regressions\n",
    "y = data.Moisture\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6146f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA scree plot\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58894408",
   "metadata": {},
   "source": [
    "4 components seems a proper number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5568bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Proportion of Variance Explained : \", pca.explained_variance_ratio_)  \n",
    "   \n",
    "out_sum = np.cumsum(pca.explained_variance_ratio_)  \n",
    "print (\"Cumulative Prop. Variance Explained: \", out_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative explained variance ratio\n",
    "plt.plot(PC_values, np.cumsum(pca.explained_variance_ratio_), 'ro-', linewidth=2)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Cumulative Prop. Variance Explained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA producing the reduced variable Xreg with a proper number of components\n",
    "pca = PCA(n_components=3)\n",
    "Xreg = pca.fit_transform(X_snv_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da3c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the scores\n",
    "scores = pd.DataFrame(data = Xreg, columns = ['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Scores - for graphs\n",
    "scores = pd.concat([scores, y], axis = 1)\n",
    "\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7178ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', 'PC3'], index=data.columns[1:176])\n",
    "loadings[\"Wavelengths\"] = wl\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93215780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores plot\n",
    "import plotly.express as px\n",
    "fig = px.scatter(scores, x=\"PC1\", y=\"PC2\", hover_data={'Sample': (scores.index)})\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Scores Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores plot\n",
    "import plotly.express as px\n",
    "fig = px.scatter(scores, x=\"PC1\", y=\"PC2\", color=\"Moisture\", hover_data={'Sample': (scores.index)})\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Scores Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(loadings, x=\"PC1\", y=\"PC2\",text=\"Wavelengths\")\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Loadings Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(loadings, x=\"Wavelengths\", y=\"PC1\")\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Loadings Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9ff44",
   "metadata": {},
   "source": [
    "## Principal Component Regression (PCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y for regression\n",
    "y = data.Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583535c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X for regression\n",
    "scores = scores.iloc[:,0:3]\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f97974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object \n",
    "regr = linear_model.LinearRegression() \n",
    "# Fit \n",
    "regr.fit(scores, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba50bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration \n",
    "y_c = regr.predict(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546ddec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation \n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_cv = cross_val_predict(regr, scores, y, cv=10) # k-fold of 10, random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate r2 for calibration and cross-validation \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "r2_calibration = r2_score(y, y_c) \n",
    "r2_cv = r2_score(y, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean square error for calibration and cross validation \n",
    "mse_c = mean_squared_error(y, y_c) \n",
    "mse_cv = mean_squared_error(y, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907bfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_calibration, r2_cv, mse_c, mse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcr(X,y,pc):\n",
    "    pca = PCA()\n",
    "    Xreg = pca.fit_transform(X)[:,:pc]\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(Xreg, y)\n",
    "    y_c = regr.predict(Xreg)\n",
    "    y_cv = cross_val_predict(regr, Xreg, y, cv=10)\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    "    mse_c = mean_squared_error(y, y_c)\n",
    "    mse_cv = mean_squared_error(y, y_cv)\n",
    "    return(y_cv, score_c, score_cv, mse_c, mse_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr(X_snv_savgol,y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147d124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcr(X_snv_savgol,y,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bac112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcr(X_snv_savgol,y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bfcea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted, r2r, r2cv, mser, mscv = pcr(X_snv_savgol,y, pc=4)\n",
    " \n",
    "# Regression plot\n",
    "z = np.polyfit(y, predicted, 1)\n",
    "with plt.style.context(('ggplot')):\n",
    "    fig, ax = plt.subplots(figsize=(9, 5))\n",
    "    ax.scatter(y, predicted, c='red', edgecolors='k')\n",
    "    ax.plot(y, z[1]+z[0]*y, c='blue', linewidth=1)\n",
    "    ax.plot(y, y, color='green', linewidth=1)\n",
    "    plt.title('$R^{2}$ (CV): '+str(round(r2cv,4)))\n",
    "    plt.xlabel('Measured Moisture')\n",
    "    plt.ylabel('Predicted Moisture')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ba51c",
   "metadata": {},
   "source": [
    "The green line represents the ideal, 100%, correlation between measured and predicted values. The blue line is the actual correlation.  With R^{2}=0.9... the result is great, but a number of other things are required to improve this figure. Things about multiplicative scatter correction and feature selection are often used to improve the prediction. At the same time, the main limitation of the PCR approach (the fact the PCA is done without knowledge of the y values) also plays a big role in the final results.\n",
    "\n",
    "Typically, better results can be obtained with Partial Least Squares (PLS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1246ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d29390",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals = predicted - np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215fc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals = pd.DataFrame(my_residuals, columns = ['pcr_residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c9da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(data=my_residuals, x=\"pcr_residuals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1cf17",
   "metadata": {},
   "source": [
    "## Partial Least Squares (PLS) regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f2340",
   "metadata": {},
   "source": [
    "PLS, acronym of Partial Least Squares, is a widespread regression technique used to analyse near-infrared spectroscopy data. If you know a bit about NIR spectroscopy, you sure know very well that NIR is a secondary method and NIR data needs to be calibrated against primary reference data of the parameter one seeks to measure. This calibration must be done the first time only. Once the calibration is done, and is robust, one can go ahead and use NIR data to predict values of the parameter of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42a2623",
   "metadata": {},
   "source": [
    "Both PLS and PCR perform multiple linear regression, that is they build a linear model, Y=XB+E. Using a common language in statistics, X is the predictor and Y is the response. In NIR analysis, X is the set of spectra, Y is the quantity – or quantities- we want to calibrate for. Finally E is an error.\n",
    "\n",
    "The matrix X contains highly correlated data and this correlationmay obscure the variations we want to measure, that is the variations of the Y content. Both PCR and PLS will get rid of the correlation.\n",
    "\n",
    "In PCR, the set of measurements X is transformed into an equivalent set X’=XW by a linear transformation W, such that all the new ‘spectra’ (which are the principal components) are linearly independent. In statistics X’ is called the factor scores. The linear transformation in PCR is such that it minimises the covariance between the different rows of X’. That means this process only uses the spectral data, not the response values.\n",
    "\n",
    "This is the key difference between PCR and PLS regression. PLS is based on finding a similar linear transformation, but accomplishes the same task by maximising the covariance between Y and X’. In other words, PLS takes into account both spectra and response values and in doing so will improve on some of the limitations on PCR. For these reasons PLS is one of the staples of modern chemometrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    " \n",
    "# Define PLS object\n",
    "pls = PLSRegression(n_components=10)\n",
    " \n",
    "# Fit\n",
    "pls.fit(X_snv_savgol, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758caa8",
   "metadata": {},
   "source": [
    "As you can see, sklearn has already got a PLS packagw. So, first we define the number of components we want to keep in our PLS regression. I decided to keep 10 components for the sake of this example, but later will use that as a free parameter to be optimised. Once the PLS object is defined, we fit the regression to the data X (the predictor) and y (the known response). The third step is to use the model we just built to run a cross-validation experiment using 10 folds cross-validation. When we do not have a large number of spectra, cross-validation is a good way to test the predictive ability of our calibration.\n",
    "\n",
    "To check how good our calibration is, we measure the usual metrics. We’ll evaluate these metrics by comparing the result of the cross-validation y_cv with the known responses. To optimise the parameters of our PLS regression (for instance pre-processing steps and number of components) we’ll just track those metrics, most typically the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a1fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "y_cv = cross_val_predict(pls, X_snv_savgol, y, cv=3)\n",
    " \n",
    "# Calculate scores\n",
    "pls_r2 = r2_score(y, y_cv)\n",
    "mse = mean_squared_error(y, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0160f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8036fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.values[:, 1:176]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72aadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate second derivative\n",
    "X2 = savgol_filter(X, 7, polyorder = 2,deriv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b93237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot second derivative\n",
    "plt.figure(figsize=(15,15))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(wl, X2.T)\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('Absorbance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f8e771",
   "metadata": {},
   "source": [
    "The offset is gone and the data look more bunched together.\n",
    "\n",
    "Now it’s time to get to the optimisation of the PLS regression. As anticipated above, we want to run a PLS regression with a variable number of components and test its performance in cross-validation. In practice we want to find the number of components that minimises the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef2856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16965d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_pls_cv(X, y, n_comp, plot_components=True):\n",
    " \n",
    "    '''Run PLS including a variable number of components, up to n_comp,\n",
    "       and calculate MSE '''\n",
    " \n",
    "    mse = []\n",
    "    component = np.arange(1, n_comp)\n",
    " \n",
    "    for i in component:\n",
    "        pls = PLSRegression(n_components=i)\n",
    " \n",
    "        # Cross-validation\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    " \n",
    "        mse.append(mean_squared_error(y, y_cv))\n",
    " \n",
    "        comp = 100*(i+1)/40\n",
    "        # Trick to update status on the same line\n",
    "        stdout.write(\"\\r%d%% completed\" % comp)\n",
    "        stdout.flush()\n",
    "    stdout.write(\"\\n\")\n",
    " \n",
    "    # Calculate and print the position of minimum in MSE\n",
    "    msemin = np.argmin(mse)\n",
    "    print(\"Suggested number of components: \", msemin+1)\n",
    "    stdout.write(\"\\n\")\n",
    " \n",
    "    if plot_components is True:\n",
    "        with plt.style.context(('ggplot')):\n",
    "            plt.plot(component, np.array(mse), '-v', color = 'blue', mfc='blue')\n",
    "            plt.plot(component[msemin], np.array(mse)[msemin], 'P', ms=10, mfc='red')\n",
    "            plt.xlabel('Number of PLS components')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.title('PLS')\n",
    "            plt.xlim(left=-1)\n",
    " \n",
    "        plt.show()\n",
    " \n",
    "    # Define PLS object with optimal number of components\n",
    "    pls_opt = PLSRegression(n_components=msemin+1)\n",
    " \n",
    "    # Fir to the entire dataset\n",
    "    pls_opt.fit(X, y)\n",
    "    y_c = pls_opt.predict(X)\n",
    " \n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls_opt, X, y, cv=10)\n",
    " \n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    " \n",
    "    # Calculate mean squared error for calibration and cross validation\n",
    "    mse_c = mean_squared_error(y, y_c)\n",
    "    mse_cv = mean_squared_error(y, y_cv)\n",
    " \n",
    "    print('R2 calib: %5.3f'  % score_c)\n",
    "    print('R2 CV: %5.3f'  % score_cv)\n",
    "    print('MSE calib: %5.3f' % mse_c)\n",
    "    print('MSE CV: %5.3f' % mse_cv)\n",
    " \n",
    "    # Plot regression and figures of merit\n",
    "    rangey = max(y) - min(y)\n",
    "    rangex = max(y_c) - min(y_c)\n",
    " \n",
    "    # Fit a line to the CV vs response\n",
    "    z = np.polyfit(y, y_c, 1)\n",
    "    with plt.style.context(('ggplot')):\n",
    "        fig, ax = plt.subplots(figsize=(9, 5))\n",
    "        ax.scatter(y_c, y, c='red', edgecolors='k')\n",
    "        #Plot the best fit line\n",
    "        ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)\n",
    "        #Plot the ideal 1:1 line\n",
    "        ax.plot(y, y, color='green', linewidth=1)\n",
    "        plt.title('$R^{2}$ (CV): '+str(round(score_cv,4)))\n",
    "        plt.xlabel('Predicted $^{\\circ}$')\n",
    "        plt.ylabel('Measured $^{\\circ}$')\n",
    " \n",
    "        plt.show()\n",
    " \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47f6c5",
   "metadata": {},
   "source": [
    "This function first runs a loop over the number of PLS components and calculates the MSE of prediction.  Secondly, it finds the number of components that minimises the MSE and uses that value to run a PLS again. A bunch of metrics is calculated and printed the second time around.\n",
    "\n",
    "Let’s run this function by setting the maximum number of components to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75bca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimise_pls_cv(X_snv_savgol,y, 20, plot_components=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b51f2f",
   "metadata": {},
   "source": [
    "The first plot that’ll come up is the MSE as a function of the number of components. The suggested number of components that minimises the MSE is highlighted on the plot.\n",
    "\n",
    "The second plot is the actual regression figure, including the metrics for the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ab437f",
   "metadata": {},
   "source": [
    "The model seems to work well on both calibration and validation data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1328e1",
   "metadata": {},
   "source": [
    "We can try to optimize it using a variable selection approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247aaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_opt = PLSRegression(n_components=3)\n",
    "pls_opt.fit(X_snv_savgol, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_opt.x_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08510ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n",
    "scores = pd.DataFrame(data = pls_opt.x_scores_, columns = ['LV1', 'LV2', 'LV3'])\n",
    "\n",
    "# Scores - for graphs\n",
    "scores = pd.concat([scores, y], axis = 1)\n",
    "\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515ede5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Scores\n",
    "pls_opt.x_loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec8b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings\n",
    "loadings = pd.DataFrame(pls_opt.x_loadings_,columns=['LV1', 'LV2', 'LV3'], index=data.columns[1:176])\n",
    "loadings[\"Wavelengths\"] = wl\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scores plot\n",
    "import plotly.express as px\n",
    "fig = px.scatter(scores, x=\"LV1\", y=\"LV2\", color=\"Moisture\", hover_data={'Sample': (scores.index)})\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Scores Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c976f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loadings plot\n",
    "fig = px.line(loadings, x=\"Wavelengths\", y=\"LV1\")\n",
    "# fig = px.scatter(loadings, x=\"LV1\", y=\"LV2\",hover_data={'Wavelength': (loadings.Wavelengths)})\n",
    "fig.update_xaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='Black')\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=800,\n",
    "    title_text='Loadings Plot')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537096e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variables\n",
    "plt.figure(figsize=(16,16))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(wl, X[(0,38),:].T)\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('Absorbance')\n",
    "    plt.legend(['0', '38'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pls_opt.predict(X_snv_savgol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7443a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e767558",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6565c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals = np.concatenate(Y_pred)-np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_residuals = pd.DataFrame(my_residuals, columns = ['pls_residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511484c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.kdeplot(data=my_residuals, x=\"pls_residuals\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d3881a",
   "metadata": {},
   "source": [
    "## Variable selection method for PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6de60",
   "metadata": {},
   "source": [
    "The idea behind variable selection in chemometrics is that when it comes to spectral measurements not all wavelengths are created equals. In visible and NIR spectroscopy especially, it is often hard to predict in advance which wavelength bands will contain most of the signal related to the analyte we want to measure. So, as a first shot, we measure the whole range allowed by our instrument, and then figure out later which bands are more relevant for our calibration.\n",
    "\n",
    "To say the same thing in a bit more quantitative way, we want to check which wavelength bands lead to a better quality model. Actually, in practice, we check which bands give a worse quality model, so we can get rid of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c0d60",
   "metadata": {},
   "source": [
    "### Feature selection by filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bace4c",
   "metadata": {},
   "source": [
    "Feature selection by filtering is one of the simplest ways of performing wavelength selection.\n",
    "\n",
    "The idea behind this method is very simple, and can be summarised in the following:\n",
    "\n",
    " - Optimise the PLS regression using the full spectrum, for instance using cross-validation or prediction data to quantify its quality.\n",
    " - Extract the regression coefficients form the best model. Each regression coefficient uniquely associates each wavelength with the response. A low absolute value of the regression coefficient means that specific wavelength has a low correlation with the quantity of interest.\n",
    " - Discard the lowest correlation wavelengths according to some rule. These wavelengths are the ones that typically worsen the quality of the calibration model, therefore by discarding them effectively we expect to improve the metrics associated with our prediction or cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da4c43",
   "metadata": {},
   "source": [
    "One way to discard the lowest correlation wavelengths is to set a threshold and get rid of all wavelengths whose regression coefficients (in absolute value) fall below that threshold. However this method is very sensitive to the choice of threshold, which tends to be a subjective choice, or requires a trial-and-error approach.\n",
    "\n",
    "Another approach, that is much less subjective, is to discard one wavelength at a time (the one with the lowest absolute value of the associated regression coefficient) and rebuild the calibration model. By choosing the MSE (means square error) of prediction or cross-validation as metric, the procedure is iterated until the MSE decreases. At some point, removing wavelengths will produce a worse calibration, and that is the stopping criterion for the optimisation algorithm.\n",
    "\n",
    "Alternatively, one could simply remove a fixed number of wavelengths iteratively, and then check for which number of removed wavelengths the MSE is minimised. Either way we have a method that does not depend on the subjective choice of the threshold and can be applied without changes regardless of the data set being analysed.\n",
    "\n",
    "One caveat of this method, at least in its simple implementation is that it may get a bit slow for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import stdout\n",
    " \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from scipy.signal import savgol_filter\n",
    " \n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6321168",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PLS regression object\n",
    "pls = PLSRegression(n_components=3)\n",
    "# Fit data\n",
    "pls.fit(X_snv_savgol, y)\n",
    " \n",
    "# Plot spectra\n",
    "plt.figure(figsize=(8,9))\n",
    "with plt.style.context(('ggplot')):\n",
    "    ax1 = plt.subplot(211)\n",
    "    plt.plot(wl, X_snv_savgol.T)\n",
    "    plt.ylabel('My data')\n",
    " \n",
    "    ax2 = plt.subplot(212, sharex=ax1)\n",
    "    plt.plot(wl, np.abs(loadings.LV1))\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    "    plt.ylabel('Absolute value of Loadings LV1')\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b6207",
   "metadata": {},
   "source": [
    "What we have done is a basic PLS regression with *n* components and used it to fit the first derivative data. The PLS coefficients of this fit can be accessed by pls Loadings, that is the first (and in this case only) column of the pls.coef_ object. It is worth reiterating that these are the regression coefficients that quantify the strength of the association between each wavelength and the response. We are interested only in the absolute value of these coefficients, as large positive and large negative coefficients are equally important for our regression, denoting large positive or large negative correlation with the response respectively. In other words we want to identify and discard the regression coefficients that are close to zero: they are the ones with poor correlation with the response.\n",
    "\n",
    "The association between each coefficient and the spectral feature can be visualised using the the second part of the code above, producing this plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6834",
   "metadata": {},
   "source": [
    "As you can see, a number of wavelengths are associated with fairly small regression coefficients. We want to use this basic idea to identify and discard small coefficients iteratively, starting from the smallest, and optimise the PLS regression at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913c377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of indices that sorts the PLS coefficients in ascending order \n",
    "# of the absolute value\n",
    "sorted_ind = np.argsort(np.abs(loadings.LV1))\n",
    " \n",
    "# Sort spectra according to ascending absolute value of PLS coefficients\n",
    "Xc = X_snv_savgol[:,sorted_ind]\n",
    "Xc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2d6e6",
   "metadata": {},
   "source": [
    "What we have done is to extract the sequence of indices corresponding to sorting the absolute value of the PLS regression coefficients in ascending order, and use that sequence to sort the spectra accordingly. Note that sorting the spectral component according to the strength of the associated PLS coefficients has no influence whatsoever on the PLS regression, but it enables us to easily discard one component at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pls_variable_selection(X, y, max_comp):\n",
    "    \n",
    "    # Define MSE array to be populated\n",
    "    mse = np.zeros((max_comp,X.shape[1]))\n",
    " \n",
    "    # Loop over the number of PLS components\n",
    "    for i in range(max_comp):\n",
    "        \n",
    "        # Regression with specified number of components, using full spectrum\n",
    "        pls1 = PLSRegression(n_components=i+1)\n",
    "        pls1.fit(X, y)\n",
    "        \n",
    "        # Indices of sort spectra according to ascending absolute value of PLS coefficients\n",
    "        sorted_ind = np.argsort(np.abs(loadings.LV1))\n",
    " \n",
    "        # Sort spectra accordingly \n",
    "        Xc = X[:,sorted_ind]\n",
    " \n",
    "        # Discard one wavelength at a time of the sorted spectra,\n",
    "        # regress, and calculate the MSE cross-validation\n",
    "        for j in range(Xc.shape[1]-(i+1)):\n",
    " \n",
    "            pls2 = PLSRegression(n_components=i+1)\n",
    "            pls2.fit(Xc[:, j:], y)\n",
    "            \n",
    "            y_cv = cross_val_predict(pls2, Xc[:, j:], y, cv=5)\n",
    " \n",
    "            mse[i,j] = mean_squared_error(y, y_cv)\n",
    "    \n",
    "        comp = 100*(i+1)/(max_comp)\n",
    "        stdout.write(\"\\r%d%% completed\" % comp)\n",
    "        stdout.flush()\n",
    "    stdout.write(\"\\n\")\n",
    " \n",
    "    # # Calculate and print the position of minimum in MSE\n",
    "    mseminx,mseminy = np.where(mse==np.min(mse[np.nonzero(mse)]))\n",
    " \n",
    "    print(\"Optimised number of PLS components: \", mseminx[0]+1)\n",
    "    print(\"Wavelengths to be discarded \",mseminy[0])\n",
    "    print('Optimised MSEP ', mse[mseminx,mseminy][0])\n",
    "    stdout.write(\"\\n\")\n",
    "    # plt.imshow(mse, interpolation=None)\n",
    "    # plt.show()\n",
    " \n",
    " \n",
    "    # Calculate PLS with optimal components and export values\n",
    "    pls = PLSRegression(n_components=mseminx[0]+1)\n",
    "    pls.fit(X, y)\n",
    "        \n",
    "    sorted_ind = np.argsort(np.abs(loadings.LV1))\n",
    " \n",
    "    Xc = X[:,sorted_ind]\n",
    " \n",
    "    return(Xc[:,mseminy[0]:],mseminx[0]+1,mseminy[0], sorted_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e136b09",
   "metadata": {},
   "source": [
    "The following function function works by running a PLS regression with a given number of components (up to a specified maximum), then filtering out one regression coefficient at a time up to the maximum number allowed. All data are stored in the 2D array mse. At the end of the double loop we search for the global minimum of mse excluding the zeros. That will give us the number of components and the wavelength bands that corresponds to the optimal cross-validation MSE.\n",
    "\n",
    "To give you an idea of the huge improvement we can get with this approach, let’s compare the result obtained using the full spectrum with the one optimised by variable selection. We start by defining a function to perform simple PLS with a fixed number of components, and calculate the metrics in cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8306ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_pls_cv(X, y, n_comp):\n",
    " \n",
    "    # Run PLS with suggested number of components\n",
    "    pls = PLSRegression(n_components=n_comp)\n",
    "    pls.fit(X, y)\n",
    "    y_c = pls.predict(X)\n",
    " \n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls, X, y, cv=10)    \n",
    " \n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    " \n",
    "    # Calculate mean square error for calibration and cross validation\n",
    "    mse_c = mean_squared_error(y, y_c)\n",
    "    mse_cv = mean_squared_error(y, y_cv)\n",
    " \n",
    "    print('R2 calib: %5.3f'  % score_c)\n",
    "    print('R2 CV: %5.3f'  % score_cv)\n",
    "    print('MSE calib: %5.3f' % mse_c)\n",
    "    print('MSE CV: %5.3f' % mse_cv)\n",
    " \n",
    "    # Plot regression \n",
    " \n",
    "    z = np.polyfit(y, y_cv, 1)\n",
    "    with plt.style.context(('ggplot')):\n",
    "        fig, ax = plt.subplots(figsize=(9, 5))\n",
    "        ax.scatter(y_cv, y, c='red', edgecolors='k')\n",
    "        ax.plot(z[1]+z[0]*y, y, c='blue', linewidth=1)\n",
    "        ax.plot(y, y, color='green', linewidth=1)\n",
    "        plt.title('$R^{2}$ (CV): '+str(score_cv))\n",
    "        plt.xlabel('Predicted $^{\\circ}$Brix')\n",
    "        plt.ylabel('Measured $^{\\circ}$Brix')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf3e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_Xc, ncomp, wav, sorted_ind = pls_variable_selection(X_snv_savgol, y, 3)\n",
    "simple_pls_cv(opt_Xc, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddffbe5",
   "metadata": {},
   "source": [
    "As a sanity check, we can plot the discarded bands on top of the absorbance spectra. The code is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d123964",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a boolean array according to the indices that are being discarded\n",
    "ix = np.in1d(wl.ravel(), wl[sorted_ind][:wav])\n",
    " \n",
    "import matplotlib.collections as collections\n",
    " \n",
    "# Plot spectra with superimpose selected bands\n",
    "fig, ax = plt.subplots(figsize=(8,9))\n",
    "with plt.style.context(('ggplot')):\n",
    "    ax.plot(wl, X_snv_savgol.T)\n",
    "    plt.ylabel('First derivative absorbance spectra')\n",
    "    plt.xlabel('Wavelength (nm)')\n",
    " \n",
    "collection = collections.BrokenBarHCollection.span_where(\n",
    "    wl, ymin=-2, ymax=2, where=ix == True, facecolor='red', alpha=0.3)\n",
    "ax.add_collection(collection)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709819fc",
   "metadata": {},
   "source": [
    "## Outlier detection - works for PCA, PCR and PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ee9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PLS object\n",
    "pls = PLSRegression(n_components=8)\n",
    "# Fit data\n",
    "pls.fit(X_snv_savgol, y)\n",
    " \n",
    "# Get X scores\n",
    "T = pls.x_scores_\n",
    "# Get X loadings\n",
    "P = pls.x_loadings_"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAAAdCAYAAADRjkxMAAAIMklEQVR4nO2bf2wT5xnHP10mS9EOZTOr4maqaYVHlEuqGVCNJhmqJa7agDCgZlQLi7qo6oLFQldY1IUIpSkKrAtscrIoA9QVlDYVS6SCJxakNpE6gkQsBXsaORTqauBt4TrAVdarsp6wbn84TvwrthMSx9Lu85fzvve+73Pvfd/nfd7nLo9omqaho5PHfG2lDdDRyYQuUp285+srbYDO/xfqlWPsemMEocSIAVA/lwmFBUzfFiIXfBlCLmmgt9OJaaaNLlKdnCKNydSfvUhNCYDKyNFttH3ZSE97JQJAaJCmP6yeFSjo271OLgn7GS1smBEoQIDxa2DZICJEiwpXYTGZ4prpItXJHZ9KrHpanPt7UsI/ZUBcGyPK/4RY/WS8SNNu98qV3+A65YvECVMqYMA4E0vMElYIfaagAmDlwLkOqo0PeTMPjcLIb12c9KuEJkMztgEGAfEVN+6dZlC9dNW14QlFayP3Zv2Jm+Yf5PgGpkc4VtPGsAqGIhPGb8yUR+fdEBOzxcy3uP8c7u0rM9nq2ElcnSOo82pDJXRPxbTBScPP6rEVA+tqqY3tI/AJAezsKY0pLHZSU5wwmJYFdz7YrzkcDs3Rfln7KtUFD+5oQ+07NYejU/Nl02EOuX/pFxHbHSe00QcJlQ9GtROO3dobH4xr9xPrcshXHx/VHD86qg3J8eU+91bN4XBoP+69HV/xr35tv2Or1pkHk/3Fh4ci89sxmlz54LbW//OtmsOxW+v0JSvH97utmqPxgnYnwxhZbPcqAUkCQBQt8V40SoGJyl3PI5SsZsWdaALGLTuoNAAMMXRVjalR8Hd3cXufm9adIsaCFTIQFe+Il5pDzVTGeZAg0pgKCNg3muOblNjZvNbCmu/k0Mx5CEz4AbBZxeTKAjP2ZyxACE//CEpcZRDJqyI8ZcGU3DKOLEQq4bsCICCWpunO+BhmozAXAOcLhXZ2bBcAleE/DRECIgJ1cYKDtO/MNEXLzLSXy3/fQ3VFQvldP6OTADbKn0hsJHNn0oL50ZxYmIaI0EBk01Opn3zobjDy4wslXqRTAcYnwVZqyThKZpHekvCqAJtZvy62Qmbw+ACBWWvuEHzSnHeeFEC0Px9ZPGPDjIZAPt/CifBBevZbV3xRqdcuI2+zY04svzGOBFBRjliYUDkVQl67JqlNEkoA/00l01UoN71IoaxNjrEjIjSKRCyJcSQQEXFkfONGMd5jBsbxI1JelnJvjiOjSJXAODJAhQVL7JYY8jH8uXFuYGM5P63MvCpWhIpq9jwB4Gfg1000fVxFx76VFyiA4elGOrYne/PAhBcA00Zr8sIX7DQfdWZ2CIUCwR4XXWPzC1W52Ufbr0ZRM2slmQk/XsCwZRMpNnu4MUj/LeBRJ80vxGsjeMOLWiRiyWI3yChSyZ9issIhvO+eQYnNbxXbqa7Ih8eeCjP2bZFpDI4J1B9xYlqxGDQBg4AhyRYZaUwBDNjKUvjLAgNCondNRYEJ55FWVr/rosubLNSIQO+zp7MR6yIenfTXywBYxQTnFFaRr57E9foAyrpa3Kei/Qfo21dH3Ut1NP1RhulLHHupDlenl3T+PsMbJwnf1cgv+ezLPHs2tk6gpnOh8ZyMZ18dXTcX2AwwvODm4t6U6zUrTKIVIxIh/HxyCyoTY8B8YkrC9ymAnfWLv+UIgoXaI630HXbRRQ+NtogaH1agIBP4W0Ra3rd28exbczWGIhPmMjvVrb04N8ZqxEJtd29cGiob0ot0UsI/BVBJq6cZe3T13vXQVBtIiFGzwYSz+0OcC232sCh+ut70Y64wELqu4Lk4Qn2FPXWmIh8IjOMHKCvHko3HzESCUOu/6aHlzfvU/36xAgWmJEZvAEU1uAcaUm/3S0T6ZL7kixyMbJuwJkyWarMizm5TMoOH+1j1+gHs+bbjh2U8h0/Aaz108A7bfulB/egy3v32uUWXNdGXBAtrZappp2N7xmPOLNK1YVTIKj2TNTNCfefQi7x4r4rWUwcWL1CYW0gbylnuk0hakQakyNMwlVniDxkFIvV7TXNl1y9wRrDRm28CRcHf3cTQMx24NwoQrsJZ5GFgapgLf2nA/txCcxEC9td6sS+LrVHmttHN31ta/6RMDDKsVlFV7GPoWgjblsXnYqILyVI6T+58CUkj0mgy2YCtIsELGC1YZ+8vxPD7fn64tyELY3MZkypIp5t4z9g6lwstEKnebWbgdBD/wDDB52oyp3FyzXSA8RsANqylmS7OHmWsC9dpA83HGxELZTwtTbSp7bQ6FuOrowtJwCouf555fpF+Fk0m21mfZrIU7xm6wk7efjyb4XIXk8rnWzg23UDPK/G7gPn71ZhPnyR46wIjt2qoTUqUrzATPkYASsqxFC1Nl4q3C9f7q2k9XotFADDhbG+HlhbaWIRQo/FoyhcNS8+8KSh1Ik0yGSAcQjrfxsstQ9i2V+VPEj+sEDjfxqvda2hMlQt9vJIdFQAy/Zek3NuXgeB1LypgsIlL4uUjAn2M9lmBzlAQEermkTbaPpIX1mk0Hl373aU52KXjrodHNC32H/GCeJpa6P83KPdkFBUoNGL6VsJG/t8QcvTroaIa3OcaYg5RK4P85xaazgXivnoyGKtpfjvmMHezD9fh9wjEfPkkFBsRjDto7axZ9gNAagL07WtjcCZRODvvMV8+iXVumh2LcAP/GODVbgMH252Y53s+YZnhI8eQ69zUrk3XWSRE6P9nChtL63EfqlweRzXtTxSpjk7+oX/0rJP36CLVyXt0kerkPbpIdfIeXaQ6eY8uUp28539F5zebr7s41wAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "053ac988",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd555455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error array\n",
    "Err = X_snv_savgol - np.dot(T,P.T)\n",
    "Err"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "fee6be06",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q-residuals (sum over the rows of the error array)\n",
    "Q = np.sum(Err**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b0f1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ba650160",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb5171d",
   "metadata": {},
   "source": [
    "lambda is a diagonal matrix containing the eigenvalues corresponding to k principal components, factors, or latent variables retained in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739cc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hotelling's T-squared (data are normalised here - i.e., divided by std)\n",
    "Tsq = np.sum((pls.x_scores_/np.std(pls.x_scores_, axis=0))**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598b4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c08386",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f16791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the confidence level\n",
    "conf = 0.95\n",
    " \n",
    "from scipy.stats import f\n",
    "# Calculate confidence level for T-squared from the ppf of the F distribution\n",
    "Tsq_conf =  f.ppf(q=conf, dfn=ncomp, \\\n",
    "            dfd=X_snv_savgol.shape[0])*ncomp*(X_snv_savgol.shape[0]-1)/(X_snv_savgol.shape[0]-ncomp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399820fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tsq_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.max(Q)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98ab44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d6be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while (1 - np.sum(Q > i)/np.sum(Q > 0)) > conf:\n",
    "    i -= 1\n",
    "    Q_conf = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78cfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0d922",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the Q vs Hotelling T2\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.figure(figsize=(8,4.5))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(Tsq, Q, 'o')\n",
    " \n",
    "    plt.plot([Tsq_conf,Tsq_conf],[plt.axis()[2],plt.axis()[3]],  '--')\n",
    "    plt.plot([plt.axis()[0],plt.axis()[1]],[Q_conf,Q_conf],  '--')\n",
    "    plt.xlabel(\"Hotelling's T-squared\")\n",
    "    plt.ylabel('Q residuals')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4a535",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = {'Hotelling T2': Tsq,\n",
    "        'Q residuals': Q\n",
    "        }\n",
    "residuals = pd.DataFrame(residuals)\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.sort_values('Q residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bcb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
